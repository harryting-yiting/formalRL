{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-09T07:03:48.855866279Z",
     "start_time": "2023-09-09T07:03:48.814012081Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m obs, reward, Terminated, Truncated, info \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(a)  \u001B[38;5;66;03m# Step the environment with the sampled random action\u001B[39;00m\n\u001B[1;32m     15\u001B[0m frame \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 16\u001B[0m frame\u001B[38;5;241m.\u001B[39mappend(\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrgb_array\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (obs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3\u001B[39m:] \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m3\u001B[39m))\u001B[38;5;241m.\u001B[39mall() \u001B[38;5;66;03m# goal will be zeroed out because env is HiddenGoal\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# You can choose to initialize the random seed of the environment.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# The state of your rng will remain unaffected after the environment is constructed.\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "from metaworld.envs import (ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE,\n",
    "                            ALL_V2_ENVIRONMENTS_GOAL_HIDDEN)\n",
    "                            # these are ordered dicts where the key : value\n",
    "                            # is env_name : env_constructor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "door_open_goal_observable_cls = ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE[\"door-open-v2-goal-observable\"]\n",
    "door_open_goal_hidden_cls = ALL_V2_ENVIRONMENTS_GOAL_HIDDEN[\"door-open-v2-goal-hidden\"]\n",
    "\n",
    "env = door_open_goal_hidden_cls()\n",
    "env.reset()  # Reset environment\n",
    "a = env.action_space.sample()  # Sample an action\n",
    "obs, reward, Terminated, Truncated, info = env.step(a)  # Step the environment with the sampled random action\n",
    "frame = []\n",
    "frame.append(env.render())\n",
    "assert (obs[-3:] == np.zeros(3)).all() # goal will be zeroed out because env is HiddenGoal\n",
    "\n",
    "# You can choose to initialize the random seed of the environment.\n",
    "# The state of your rng will remain unaffected after the environment is constructed.\n",
    "env1 = door_open_goal_observable_cls(seed=5)\n",
    "env2 = door_open_goal_observable_cls(seed=5)\n",
    "\n",
    "env1.reset()  # Reset environment\n",
    "env2.reset()\n",
    "a1 = env1.action_space.sample()  # Sample an action\n",
    "a2 = env2.action_space.sample()\n",
    "next_obs1, _, _, _, _ = env1.step(a1)  # Step the environment with the sampled random action\n",
    "\n",
    "next_obs2, _,_, _, _ = env2.step(a2)\n",
    "assert (next_obs1[-3:] == next_obs2[-3:]).all() # 2 envs initialized with the same seed will have the same goal\n",
    "assert not (next_obs2[-3:] == np.zeros(3)).all()   # The env's are goal observable, meaning the goal is not zero'd out\n",
    "\n",
    "env3 = door_open_goal_observable_cls(seed=10)  # Construct an environment with a different seed\n",
    "env1.reset()  # Reset environment\n",
    "env3.reset()\n",
    "a1 = env1.action_space.sample()  # Sample an action\n",
    "a3 = env3.action_space.sample()\n",
    "next_obs1, _,_, _, _ = env1.step(a1)  # Step the environment with the sampled random action\n",
    "next_obs3, _,_, _, _ = env3.step(a3)\n",
    "\n",
    "assert not (next_obs1[-3:] == next_obs3[-3:]).all() # 2 envs initialized with different seeds will have different goals\n",
    "assert not (next_obs1[-3:] == np.zeros(3)).all()   # The env's are goal observable, meaning the goal is not zero'd out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T07:12:45.223238371Z",
     "start_time": "2023-09-09T07:12:45.070503086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
